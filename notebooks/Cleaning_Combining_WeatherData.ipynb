{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44980ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Hadoop + winutils\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:\\\\hadoop-3.3.6\"\n",
    "os.environ[\"PATH\"] += \";C:\\\\hadoop-3.3.6\\\\bin\"\n",
    "\n",
    "# Force Spark to use Java 17 (SAFE, only inside notebook)\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\\\Program Files\\\\Java\\\\jdk-17\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"\\\\bin;\" + os.environ[\"PATH\"]\n",
    "\n",
    "# Fix Windows JAAS getSubject error\n",
    "os.environ[\"HADOOP_USER_NAME\"] = \"root\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f812e210-0feb-45c4-9f93-84968a6019bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.235:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>612FinalProject</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1eb48438ec0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"612FinalProject\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d77c6b6-ca75-43ae-8510-79f24c064ec0",
   "metadata": {},
   "source": [
    "#Cleaning and Combining Weather Data\n",
    "This step was perhaps the most energy consuming when it comes to our data apprehensions itself, and while we tried to prevent to get to the files in our database we had some manual work.\n",
    "\n",
    "https://acis.alberta.ca/weather-data-viewer.jsp  \n",
    "\n",
    "To access weather data you could choose a weather station, and then from there download the data you needed (daily, hourly ect), of your choice, this website however enforced a CAPTCHA which for our skillset prevented an automated request, what also was interesting was that because our AESO DATA had it's own specific \"regions\", we had to be diligent to choose a weather station that we believed existed within the defined AESO region.  \n",
    "\n",
    "We referenced this AESO MAP, which shows the boundaries of each Region that is used for our AESO Load Data.  \n",
    "https://www.arcgis.com/apps/View/index.html?appid=88859e0179b44b47b3e77b0b384a18a7  \n",
    "\n",
    "This was super helpful as our Weather Data also had an interactive map on the data page which showed the location of each weather station so through overlaying them, we could effectively choose a weather station that fell within the region (this map can be seen in the weather data link provided above).\n",
    "\n",
    "This still left with the problem that limitations of our Weather data download could only be for to 184 days (while this was not ideal, it does give a great opportunity to demonstrate our data parsing and combining skills which will be done below0.  \n",
    "\n",
    "So after identifying a station that fell into each of the AESO regions, we download 3 files for each station of HOURLY weather data which corresponded to 2023-11-01 - 2024-05-05,  2024-05-06 - 2024-10-01,  and finally 2024-10-02 - 2024-12-31, these dates are apart of the download file for our WEATHER DATA and together represent the timeline of our AESO LOAD data which is from 2023-11-01 - 2024-12-31 also HOURLY so this was inetntional so that of course we can match our data sets perfectly.  \n",
    "\n",
    "However because our decisions of Weather Data Station belonging to a AESO region was a manual decision with no clear way to automate, each weather station CSV was just renamed at the end by adding the Region of our Choice (numerical number) to the end of the CSV name, which is found in our data folder under WeatherDataRaw, as everything is untouched and represents 42 Weather Stations data (representing the 42 Aeso Regions) x 3 (as we had to download the weather data again in chunks of 3 for each station.  \n",
    "\n",
    "Below is our process of combining the 3 sets of data for the station into 1 dataframe for each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c43c68-4890-4ef0-baff-8538c79e71c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 126 weather CSV files\n",
      "Codes found: ['13', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '42', '43', '43.', '44', '45', '46', '47', '48', '49', '52', '53', '54', '55', '56', '57', '6', '60']\n",
      "Reading code 13 file: ACISHourlyData-20231101-20240505-13.csv\n",
      "Reading code 13 file: ACISHourlyData-20240506-20241001-13.csv\n",
      "Reading code 13 file: ACISHourlyData-20241002-20241231-13.csv\n",
      "Created variable 'combined_data_13' with 10247 rows\n",
      "Reading code 17 file: ACISHourlyData-20231101-20240505-17.csv\n",
      "Reading code 17 file: ACISHourlyData-20240506-20241001-17.csv\n",
      "Reading code 17 file: ACISHourlyData-20241002-20241231-17.csv\n",
      "Created variable 'combined_data_17' with 10247 rows\n",
      "Reading code 18 file: ACISHourlyData-20231101-20240505-18.csv\n",
      "Reading code 18 file: ACISHourlyData-20240506-20241001-18.csv\n",
      "Reading code 18 file: ACISHourlyData-20241002-20241231-18.csv\n",
      "Created variable 'combined_data_18' with 10247 rows\n",
      "Reading code 19 file: ACISHourlyData-20231101-20240505-19.csv\n",
      "Reading code 19 file: ACISHourlyData-20240506-20241001-19.csv\n",
      "Reading code 19 file: ACISHourlyData-20241002-20241231-19.csv\n",
      "Created variable 'combined_data_19' with 10247 rows\n",
      "Reading code 20 file: ACISHourlyData-20231101-20240505-20.csv\n",
      "Reading code 20 file: ACISHourlyData-20240506-20241001-20.csv\n",
      "Reading code 20 file: ACISHourlyData-20241002-20241231-20.csv\n",
      "Created variable 'combined_data_20' with 10247 rows\n",
      "Reading code 21 file: ACISHourlyData-20231101-20240505-21.csv\n",
      "Reading code 21 file: ACISHourlyData-20240506-20241001-21.csv\n",
      "Reading code 21 file: ACISHourlyData-20241002-20241231-21.csv\n",
      "Created variable 'combined_data_21' with 10247 rows\n",
      "Reading code 22 file: ACISHourlyData-20231101-20240505-22.csv\n",
      "Reading code 22 file: ACISHourlyData-20240506-20241001-22.csv\n",
      "Reading code 22 file: ACISHourlyData-20241002-20241231-22.csv\n",
      "Created variable 'combined_data_22' with 10247 rows\n",
      "Reading code 23 file: ACISHourlyData-20231101-20240505-23.csv\n",
      "Reading code 23 file: ACISHourlyData-20240506-20241001-23.csv\n",
      "Reading code 23 file: ACISHourlyData-20241002-20241231-23.csv\n",
      "Created variable 'combined_data_23' with 10247 rows\n",
      "Reading code 24 file: ACISHourlyData-20231101-20240505-24.csv\n",
      "Reading code 24 file: ACISHourlyData-20240506-20241001-24.csv\n",
      "Reading code 24 file: ACISHourlyData-20241002-20241231-24.csv\n",
      "Created variable 'combined_data_24' with 10247 rows\n",
      "Reading code 25 file: ACISHourlyData-20231101-20240505-25.csv\n",
      "Reading code 25 file: ACISHourlyData-20240506-20241001-25.csv\n",
      "Reading code 25 file: ACISHourlyData-20241002-20241231-25.csv\n",
      "Created variable 'combined_data_25' with 10247 rows\n",
      "Reading code 26 file: ACISHourlyData-20231101-20240505-26.csv\n",
      "Reading code 26 file: ACISHourlyData-20240506-20241001-26.csv\n",
      "Reading code 26 file: ACISHourlyData-20241002-20241231-26.csv\n",
      "Created variable 'combined_data_26' with 10247 rows\n",
      "Reading code 27 file: ACISHourlyData-20231101-20240505-27.csv\n",
      "Reading code 27 file: ACISHourlyData-20240506-20241001-27.csv\n",
      "Reading code 27 file: ACISHourlyData-20241002-20241231-27.csv\n",
      "Created variable 'combined_data_27' with 10247 rows\n",
      "Reading code 28 file: ACISHourlyData-20231101-20240505-28.csv\n",
      "Reading code 28 file: ACISHourlyData-20240506-20241001-28.csv\n",
      "Reading code 28 file: ACISHourlyData-20241002-20241231-28.csv\n",
      "Created variable 'combined_data_28' with 10247 rows\n",
      "Reading code 29 file: ACISHourlyData-20231101-20240505-29.csv\n",
      "Reading code 29 file: ACISHourlyData-20240506-20241001-29.csv\n",
      "Reading code 29 file: ACISHourlyData-20241002-20241231-29.csv\n",
      "Created variable 'combined_data_29' with 10247 rows\n",
      "Reading code 30 file: ACISHourlyData-20231101-20240505-30.csv\n",
      "Reading code 30 file: ACISHourlyData-20240506-20241001-30.csv\n",
      "Reading code 30 file: ACISHourlyData-20241002-20241231-30.csv\n",
      "Created variable 'combined_data_30' with 10247 rows\n",
      "Reading code 31 file: ACISHourlyData-20231101-20240505-31.csv\n",
      "Reading code 31 file: ACISHourlyData-20240506-20241001-31.csv\n",
      "Reading code 31 file: ACISHourlyData-20241002-20241231-31.csv\n",
      "Created variable 'combined_data_31' with 10247 rows\n",
      "Reading code 32 file: ACISHourlyData-20231101-20240505-32.csv\n",
      "Reading code 32 file: ACISHourlyData-20240506-20241001-32.csv\n",
      "Reading code 32 file: ACISHourlyData-20241002-20241231-32.csv\n",
      "Created variable 'combined_data_32' with 10247 rows\n",
      "Reading code 33 file: ACISHourlyData-20231101-20240505-33.csv\n",
      "Reading code 33 file: ACISHourlyData-20240506-20241001-33.csv\n",
      "Reading code 33 file: ACISHourlyData-20241002-20241231-33.csv\n",
      "Created variable 'combined_data_33' with 10247 rows\n",
      "Reading code 34 file: ACISHourlyData-20231101-20240505-34.csv\n",
      "Reading code 34 file: ACISHourlyData-20240506-20241001-34.csv\n",
      "Reading code 34 file: ACISHourlyData-20241002-20241231-34.csv\n",
      "Created variable 'combined_data_34' with 10247 rows\n",
      "Reading code 35 file: ACISHourlyData-20231101-20240505-35.csv\n",
      "Reading code 35 file: ACISHourlyData-20240506-20241001-35.csv\n",
      "Reading code 35 file: ACISHourlyData-20241002-20241231-35.csv\n",
      "Created variable 'combined_data_35' with 10247 rows\n",
      "Reading code 36 file: ACISHourlyData-20231101-20240505-36.csv\n",
      "Reading code 36 file: ACISHourlyData-20240506-20241001-36.csv\n",
      "Reading code 36 file: ACISHourlyData-20241002-20241231-36.csv\n",
      "Created variable 'combined_data_36' with 10247 rows\n",
      "Reading code 37 file: ACISHourlyData-20231101-20240505-37.csv\n",
      "Reading code 37 file: ACISHourlyData-20240506-20241001-37.csv\n",
      "Reading code 37 file: ACISHourlyData-20241002-20241231-37.csv\n",
      "Created variable 'combined_data_37' with 10247 rows\n",
      "Reading code 38 file: ACISHourlyData-20231101-20240505-38.csv\n",
      "Reading code 38 file: ACISHourlyData-20240506-20241001-38.csv\n",
      "Reading code 38 file: ACISHourlyData-20241002-20241231-38.csv\n",
      "Created variable 'combined_data_38' with 10247 rows\n",
      "Reading code 39 file: ACISHourlyData-20231101-20240505-39.csv\n",
      "Reading code 39 file: ACISHourlyData-20240506-20241001-39.csv\n",
      "Reading code 39 file: ACISHourlyData-20241002-20241231-39.csv\n",
      "Created variable 'combined_data_39' with 10247 rows\n",
      "Reading code 4 file: ACISHourlyData-20231101-20240505-4.csv\n",
      "Reading code 4 file: ACISHourlyData-20240506-20241001-4.csv\n",
      "Reading code 4 file: ACISHourlyData-20241002-20241231-4.csv\n",
      "Created variable 'combined_data_4' with 10247 rows\n",
      "Reading code 40 file: ACISHourlyData-20231101-20240505-40.csv\n",
      "Reading code 40 file: ACISHourlyData-20240506-20241001-40.csv\n",
      "Reading code 40 file: ACISHourlyData-20241002-20241231-40.csv\n",
      "Created variable 'combined_data_40' with 10247 rows\n",
      "Reading code 42 file: ACISHourlyData-20231101-20240505-42.csv\n",
      "Reading code 42 file: ACISHourlyData-20240506-20241001-42.csv\n",
      "Reading code 42 file: ACISHourlyData-20241002-20241231-42.csv\n",
      "Created variable 'combined_data_42' with 10247 rows\n",
      "Reading code 43 file: ACISHourlyData-20231101-20240505-43.csv\n",
      "Reading code 43 file: ACISHourlyData-20241002-20241231-43.csv\n",
      "Created variable 'combined_data_43' with 6671 rows\n",
      "Reading code 44 file: ACISHourlyData-20231101-20240505-44.csv\n",
      "Reading code 44 file: ACISHourlyData-20240506-20241001-44.csv\n",
      "Reading code 44 file: ACISHourlyData-20241002-20241231-44.csv\n",
      "Created variable 'combined_data_44' with 10247 rows\n",
      "Reading code 45 file: ACISHourlyData-20231101-20240505-45.csv\n",
      "Reading code 45 file: ACISHourlyData-20240506-20241001-45.csv\n",
      "Reading code 45 file: ACISHourlyData-20241002-20241231-45.csv\n",
      "Created variable 'combined_data_45' with 10247 rows\n",
      "Reading code 46 file: ACISHourlyData-20231101-20240505-46.csv\n",
      "Reading code 46 file: ACISHourlyData-20240506-20241001-46.csv\n",
      "Reading code 46 file: ACISHourlyData-20241002-20241231-46.csv\n",
      "Created variable 'combined_data_46' with 10247 rows\n",
      "Reading code 47 file: ACISHourlyData-20231101-20240505-47.csv\n",
      "Reading code 47 file: ACISHourlyData-20240506-20241001-47.csv\n",
      "Reading code 47 file: ACISHourlyData-20241002-20241231-47.csv\n",
      "Created variable 'combined_data_47' with 10247 rows\n",
      "Reading code 48 file: ACISHourlyData-20231101-20240505-48.csv\n",
      "Reading code 48 file: ACISHourlyData-20240506-20241001-48.csv\n",
      "Reading code 48 file: ACISHourlyData-20241002-20241231-48.csv\n",
      "Created variable 'combined_data_48' with 10247 rows\n",
      "Reading code 49 file: ACISHourlyData-20231101-20240505-49.csv\n",
      "Reading code 49 file: ACISHourlyData-20240506-20241001-49.csv\n",
      "Reading code 49 file: ACISHourlyData-20241002-20241231-49.csv\n",
      "Created variable 'combined_data_49' with 10247 rows\n",
      "Reading code 52 file: ACISHourlyData-20231101-20240505-52.csv\n",
      "Reading code 52 file: ACISHourlyData-20240506-20241001-52.csv\n",
      "Reading code 52 file: ACISHourlyData-20241002-20241231-52.csv\n",
      "Created variable 'combined_data_52' with 10247 rows\n",
      "Reading code 53 file: ACISHourlyData-20231101-20240505-53.csv\n",
      "Reading code 53 file: ACISHourlyData-20240506-20241001-53.csv\n",
      "Reading code 53 file: ACISHourlyData-20241002-20241231-53.csv\n",
      "Created variable 'combined_data_53' with 10247 rows\n",
      "Reading code 54 file: ACISHourlyData-20231101-20240505-54.csv\n",
      "Reading code 54 file: ACISHourlyData-20240506-20241001-54.csv\n",
      "Reading code 54 file: ACISHourlyData-20241002-20241231-54.csv\n",
      "Created variable 'combined_data_54' with 10247 rows\n",
      "Reading code 55 file: ACISHourlyData-20231101-20240505-55.csv\n",
      "Reading code 55 file: ACISHourlyData-20240506-20241001-55.csv\n",
      "Reading code 55 file: ACISHourlyData-20241002-20241231-55.csv\n",
      "Created variable 'combined_data_55' with 10247 rows\n",
      "Reading code 56 file: ACISHourlyData-20231101-20240505-56.csv\n",
      "Reading code 56 file: ACISHourlyData-20240506-20241001-56.csv\n",
      "Reading code 56 file: ACISHourlyData-20241002-20241231-56.csv\n",
      "Created variable 'combined_data_56' with 10247 rows\n",
      "Reading code 57 file: ACISHourlyData-20231101-20240505-57.csv\n",
      "Reading code 57 file: ACISHourlyData-20240506-20241001-57.csv\n",
      "Reading code 57 file: ACISHourlyData-20241002-20241231-57.csv\n",
      "Created variable 'combined_data_57' with 10247 rows\n",
      "Reading code 6 file: ACISHourlyData-20231101-20240505-6.csv\n",
      "Reading code 6 file: ACISHourlyData-20240506-20241001-6.csv\n",
      "Reading code 6 file: ACISHourlyData-20241002-20241231-6.csv\n",
      "Created variable 'combined_data_6' with 10247 rows\n",
      "Reading code 60 file: ACISHourlyData-20231101-20240505-60.csv\n",
      "Reading code 60 file: ACISHourlyData-20240506-20241001-60.csv\n",
      "Reading code 60 file: ACISHourlyData-20241002-20241231-60.csv\n",
      "Created variable 'combined_data_60' with 10247 rows\n",
      "Reading code 43. file: ACISHourlyData-20240506-20241001-43..csv\n",
      "Created variable 'combined_data_43.' with 3576 rows\n",
      "Done combining all station codes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "weather_dir = \"../data/WeatherDataRaw\"\n",
    "\n",
    "# Find all the ACIS files\n",
    "weather_files = glob.glob(os.path.join(weather_dir, \"ACISHourlyData-*.csv\"))\n",
    "print(f\"Found {len(weather_files)} weather CSV files\")\n",
    "\n",
    "# 1) Group file paths by station code (last piece before .csv)\n",
    "files_by_code = {}\n",
    "\n",
    "for path in weather_files:\n",
    "    fname = os.path.basename(path)             # An example of ACISHourlyData-20231101-20240505-4.csv\n",
    "    name_no_ext = fname[:-4]                   # strip \".csv\"\n",
    "    parts = name_no_ext.split(\"-\")             # ['ACISHourlyData','20231101','20240505','4']\n",
    "\n",
    "    start_date = parts[1]                      # '20231101'\n",
    "    code = parts[-1]                           # '4', '6', '13', ...\n",
    "\n",
    "    files_by_code.setdefault(code, []).append((start_date, path))\n",
    "\n",
    "print(\"Codes found:\", sorted(files_by_code.keys()))\n",
    "\n",
    "# 2) For each code, read its files in date order and make a combined DataFrame\n",
    "date_col = \"Date (Local Standard Time)\"  # This was the column in the downloaded weather data which held the date and time (again\n",
    "#this was collected hourly so it has a date and time which is standard, if we to make it one so we can sort\n",
    "\n",
    "for code, lst in files_by_code.items():\n",
    "    lst_sorted = sorted(lst, key=lambda t: t[0])  #This is the sorting of it by data so our combined data frame\n",
    "    #is in order of date which should start at November 1 2023 at 0:00 and should end at Decmeber 31st 23:00\n",
    "\n",
    "    dfs = []\n",
    "    for start_date, path in lst_sorted:\n",
    "        print(f\"Reading code {code} file:\", os.path.basename(path))\n",
    "        df = pd.read_csv(path, encoding=\"latin1\")  # encoding fix for UnicodeDecodeError -> Reference to ChatGPT to help us debug we had an error here for a while\n",
    "        dfs.append(df)\n",
    "\n",
    "    combined = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Steo to ensure that it's correctly order it's ordered by date/time, JUST A CHECK to drop for each time\n",
    "    if date_col in combined.columns:\n",
    "        combined[date_col] = pd.to_datetime(combined[date_col])\n",
    "        combined = combined.sort_values(date_col).reset_index(drop=True)\n",
    "\n",
    "    #This is now our name for our combined file which we are just calling combined_data and the respective region\n",
    "    var_name = f\"combined_data_{code}\"\n",
    "    globals()[var_name] = combined\n",
    "\n",
    "    #a check to ensure the rows are correct, ideally each combined_weather_station data should be the same length\n",
    "    #which would ensure all the downloaded data was correct with dates, and there are no mistakes in our combining process\n",
    "    #this is still straightforward\n",
    "    print(f\"Created variable '{var_name}' with {len(combined)} rows\")\n",
    "\n",
    "print(\"Done combining all station codes.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d60e48aa-a29e-4e80-9e38-d2a5a412dc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station Name</th>\n",
       "      <th>Date (Local Standard Time)</th>\n",
       "      <th>Air Temp. Inst. (°C)</th>\n",
       "      <th>Air Temp. Inst. Source Flag</th>\n",
       "      <th>Air Temp. Inst. Comment</th>\n",
       "      <th>Precip. (mm)</th>\n",
       "      <th>Precip. Source Flag</th>\n",
       "      <th>Precip. Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Medicine Hat</td>\n",
       "      <td>2023-11-01 00:00:00</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>ACTUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACTUAL</td>\n",
       "      <td>using element [Precip. 1-hr other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medicine Hat</td>\n",
       "      <td>2023-11-01 01:00:00</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>ACTUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACTUAL</td>\n",
       "      <td>using element [Precip. 1-hr other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Medicine Hat</td>\n",
       "      <td>2023-11-01 02:00:00</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>ACTUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACTUAL</td>\n",
       "      <td>using element [Precip. 1-hr other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Medicine Hat</td>\n",
       "      <td>2023-11-01 03:00:00</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>ACTUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACTUAL</td>\n",
       "      <td>using element [Precip. 1-hr other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Medicine Hat</td>\n",
       "      <td>2023-11-01 04:00:00</td>\n",
       "      <td>-6.8</td>\n",
       "      <td>ACTUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACTUAL</td>\n",
       "      <td>using element [Precip. 1-hr other]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Station Name Date (Local Standard Time)  Air Temp. Inst. (°C)  \\\n",
       "0  Medicine Hat        2023-11-01 00:00:00                  -4.6   \n",
       "1  Medicine Hat        2023-11-01 01:00:00                  -5.9   \n",
       "2  Medicine Hat        2023-11-01 02:00:00                  -6.5   \n",
       "3  Medicine Hat        2023-11-01 03:00:00                  -6.9   \n",
       "4  Medicine Hat        2023-11-01 04:00:00                  -6.8   \n",
       "\n",
       "  Air Temp. Inst. Source Flag Air Temp. Inst. Comment  Precip. (mm)  \\\n",
       "0                      ACTUAL                     NaN           0.0   \n",
       "1                      ACTUAL                     NaN           0.0   \n",
       "2                      ACTUAL                     NaN           0.0   \n",
       "3                      ACTUAL                     NaN           0.0   \n",
       "4                      ACTUAL                     NaN           0.0   \n",
       "\n",
       "  Precip. Source Flag                     Precip. Comment  \n",
       "0              ACTUAL  using element [Precip. 1-hr other]  \n",
       "1              ACTUAL  using element [Precip. 1-hr other]  \n",
       "2              ACTUAL  using element [Precip. 1-hr other]  \n",
       "3              ACTUAL  using element [Precip. 1-hr other]  \n",
       "4              ACTUAL  using element [Precip. 1-hr other]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data_4.head()    # Medicine Hat Weather Station (also the region name in AESO)\n",
    "#looks good time to move one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7496c9cf-acf4-431e-8ff8-be2d26ce0db5",
   "metadata": {},
   "source": [
    "Okay this all working beautiful as you can see above  \n",
    "\n",
    "This is exactly what we wanted as we have found all the Regions (and codes correctly), which means our data looked good, and combined data set has the same number of Rows of 10247, which means their are no rows MISSING! And from our output which we xtended the data is merged in correct order, so we have a complete set for each station from November 1st 2023 to December 31st 2024 for each weather station (again this alligns beautifully, with our AESO data which we will work on next so we can eventually combine both after that is cleaned (and combined to our Urban and Rural classifier). Awesome, perhaps there may be NANS/NULL ect for our Air Temp. Inst and Precip.(mm), but we can check for that no problem.  \n",
    "\n",
    "Lets now make all of our data into one complete data set so that we have our base for PIPELINE to be executed on it, as we learned in 612."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efe5b3eb-4774-4002-bb37-37d86e65f9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area codes in weather: [np.int64(4), np.int64(6), np.int64(13), np.int64(17), np.int64(18), np.int64(19), np.int64(20), np.int64(21), np.int64(22), np.int64(23), np.int64(24), np.int64(25), np.int64(26), np.int64(27), np.int64(28), np.int64(29), np.int64(30), np.int64(31), np.int64(32), np.int64(33), np.int64(34), np.int64(35), np.int64(36), np.int64(37), np.int64(38), np.int64(39), np.int64(40), np.int64(42), np.int64(43), np.int64(44), np.int64(45), np.int64(46), np.int64(47), np.int64(48), np.int64(49), np.int64(52), np.int64(53), np.int64(54), np.int64(55), np.int64(56), np.int64(57), np.int64(60)]\n",
      "   area_code           timestamp  temp_c  precip_mm\n",
      "0          4 2023-11-01 00:00:00    -4.6        0.0\n",
      "1          4 2023-11-01 01:00:00    -5.9        0.0\n",
      "2          4 2023-11-01 02:00:00    -6.5        0.0\n",
      "3          4 2023-11-01 03:00:00    -6.9        0.0\n",
      "4          4 2023-11-01 04:00:00    -6.8        0.0\n",
      "Saved ../data/weather_all_areas_hourly.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Using the exact loop that I printed above which gave me this list - we also of course have hard copies everywhere.\n",
    "codes = ['4', '6', '13', '17', '18', '19', '20', '21', '22', '23',\n",
    "         '24', '25', '26', '27', '28', '29', '30', '31', '32', '33',\n",
    "         '34', '35', '36', '37', '38', '39', '40', '42', '43', '44',\n",
    "         '45', '46', '47', '48', '49', '52', '53', '54', '55', '56',\n",
    "         '57', '60']\n",
    "\n",
    "frames = []\n",
    "\n",
    "for code in codes:\n",
    "    df = globals()[f\"combined_data_{code}\"].copy()\n",
    "\n",
    "    # attach area code\n",
    "    df[\"area_code\"] = int(code)\n",
    "\n",
    "    # ----- find the precipitation column, if any -----\n",
    "    precip_candidates = [\n",
    "        \"Precip. (mm)\",\n",
    "        \"Precip.(mm)\",\n",
    "        \"Precip. Amount (mm)\",\n",
    "    ]\n",
    "    precip_col = None\n",
    "    for c in precip_candidates:\n",
    "        if c in df.columns:\n",
    "            precip_col = c\n",
    "            break\n",
    "\n",
    "    # build rename map\n",
    "    rename_map = {\n",
    "        \"Date (Local Standard Time)\": \"timestamp\",\n",
    "        \"Air Temp. Inst. (°C)\": \"temp_c\",\n",
    "    }\n",
    "    if precip_col is not None:\n",
    "        rename_map[precip_col] = \"precip_mm\"\n",
    "\n",
    "    df = df.rename(columns=rename_map)\n",
    "\n",
    "    # if still no precip_mm, create it (all NaN or 0.0 depending on what you want)\n",
    "    if \"precip_mm\" not in df.columns:\n",
    "        df[\"precip_mm\"] = np.nan     # or 0.0 if you prefer\n",
    "\n",
    "    # keep only modeling columns\n",
    "    frames.append(df[[\"area_code\", \"timestamp\", \"temp_c\", \"precip_mm\"]])\n",
    "\n",
    "# combine all stations\n",
    "weather_all_pd = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# ensure timestamp is datetime\n",
    "weather_all_pd[\"timestamp\"] = pd.to_datetime(weather_all_pd[\"timestamp\"])\n",
    "\n",
    "print(\"Area codes in weather:\", sorted(weather_all_pd[\"area_code\"].unique()))\n",
    "print(weather_all_pd.head())\n",
    "\n",
    "# Now need to get it all back into the CSV so we can load it into our SPARK\n",
    "weather_all_pd.to_csv(\"../data/weather_all_areas_hourly.csv\", index=False)\n",
    "print(\"Saved ../data/weather_all_areas_hourly.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9876cd-85e3-48f5-8330-d631feeaedb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa4ccb8-e0ee-4385-99f3-12f15773c683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3414f9e6-6193-4b51-8c12-9d12b469f79f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterPythonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
